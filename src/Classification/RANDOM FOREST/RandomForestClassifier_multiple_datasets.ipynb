{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39898d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7805d8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.72      0.76       166\n",
      "           1       0.78      0.85      0.81       193\n",
      "\n",
      "    accuracy                           0.79       359\n",
      "   macro avg       0.79      0.79      0.79       359\n",
      "weighted avg       0.79      0.79      0.79       359\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82       226\n",
      "           1       0.80      0.86      0.83       222\n",
      "\n",
      "    accuracy                           0.82       448\n",
      "   macro avg       0.82      0.82      0.82       448\n",
      "weighted avg       0.82      0.82      0.82       448\n",
      "\n",
      "Accuracy using RandomForestClassifier: 82.14%\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.80      0.83       166\n",
      "           1       0.84      0.89      0.86       193\n",
      "\n",
      "    accuracy                           0.85       359\n",
      "   macro avg       0.85      0.84      0.85       359\n",
      "weighted avg       0.85      0.85      0.85       359\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.77      0.81       226\n",
      "           1       0.79      0.87      0.83       222\n",
      "\n",
      "    accuracy                           0.82       448\n",
      "   macro avg       0.82      0.82      0.82       448\n",
      "weighted avg       0.82      0.82      0.82       448\n",
      "\n",
      "Accuracy using RandomForestClassifier: 82.14%\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.74      0.78       166\n",
      "           1       0.80      0.87      0.83       193\n",
      "\n",
      "    accuracy                           0.81       359\n",
      "   macro avg       0.81      0.81      0.81       359\n",
      "weighted avg       0.81      0.81      0.81       359\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.74      0.79       226\n",
      "           1       0.76      0.86      0.81       222\n",
      "\n",
      "    accuracy                           0.80       448\n",
      "   macro avg       0.80      0.80      0.80       448\n",
      "weighted avg       0.80      0.80      0.80       448\n",
      "\n",
      "Accuracy using RandomForestClassifier: 79.69%\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82       166\n",
      "           1       0.83      0.86      0.85       193\n",
      "\n",
      "    accuracy                           0.83       359\n",
      "   macro avg       0.83      0.83      0.83       359\n",
      "weighted avg       0.83      0.83      0.83       359\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       226\n",
      "           1       0.81      0.84      0.82       222\n",
      "\n",
      "    accuracy                           0.82       448\n",
      "   macro avg       0.82      0.82      0.82       448\n",
      "weighted avg       0.82      0.82      0.82       448\n",
      "\n",
      "Accuracy using RandomForestClassifier: 82.37%\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83       166\n",
      "           1       0.85      0.87      0.86       193\n",
      "\n",
      "    accuracy                           0.85       359\n",
      "   macro avg       0.85      0.84      0.85       359\n",
      "weighted avg       0.85      0.85      0.85       359\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.84       226\n",
      "           1       0.83      0.85      0.84       222\n",
      "\n",
      "    accuracy                           0.84       448\n",
      "   macro avg       0.84      0.84      0.84       448\n",
      "weighted avg       0.84      0.84      0.84       448\n",
      "\n",
      "Accuracy using RandomForestClassifier: 83.71%\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       166\n",
      "           1       0.84      0.87      0.85       193\n",
      "\n",
      "    accuracy                           0.84       359\n",
      "   macro avg       0.84      0.84      0.84       359\n",
      "weighted avg       0.84      0.84      0.84       359\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83       226\n",
      "           1       0.82      0.84      0.83       222\n",
      "\n",
      "    accuracy                           0.83       448\n",
      "   macro avg       0.83      0.83      0.83       448\n",
      "weighted avg       0.83      0.83      0.83       448\n",
      "\n",
      "Accuracy using RandomForestClassifier: 83.04%\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82       166\n",
      "           1       0.85      0.84      0.85       193\n",
      "\n",
      "    accuracy                           0.84       359\n",
      "   macro avg       0.83      0.83      0.83       359\n",
      "weighted avg       0.84      0.84      0.84       359\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.78       226\n",
      "           1       0.76      0.84      0.80       222\n",
      "\n",
      "    accuracy                           0.79       448\n",
      "   macro avg       0.79      0.79      0.79       448\n",
      "weighted avg       0.79      0.79      0.79       448\n",
      "\n",
      "Accuracy using RandomForestClassifier: 79.02%\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.74      0.80       166\n",
      "           1       0.80      0.90      0.85       193\n",
      "\n",
      "    accuracy                           0.82       359\n",
      "   macro avg       0.83      0.82      0.82       359\n",
      "weighted avg       0.83      0.82      0.82       359\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.84       226\n",
      "           1       0.81      0.88      0.85       222\n",
      "\n",
      "    accuracy                           0.84       448\n",
      "   macro avg       0.84      0.84      0.84       448\n",
      "weighted avg       0.84      0.84      0.84       448\n",
      "\n",
      "Accuracy using RandomForestClassifier: 84.15%\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.80       166\n",
      "           1       0.82      0.87      0.84       193\n",
      "\n",
      "    accuracy                           0.82       359\n",
      "   macro avg       0.83      0.82      0.82       359\n",
      "weighted avg       0.83      0.82      0.82       359\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       226\n",
      "           1       0.82      0.86      0.84       222\n",
      "\n",
      "    accuracy                           0.83       448\n",
      "   macro avg       0.83      0.83      0.83       448\n",
      "weighted avg       0.83      0.83      0.83       448\n",
      "\n",
      "Accuracy using RandomForestClassifier: 83.26%\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81       166\n",
      "           1       0.83      0.85      0.84       193\n",
      "\n",
      "    accuracy                           0.83       359\n",
      "   macro avg       0.83      0.83      0.83       359\n",
      "weighted avg       0.83      0.83      0.83       359\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       226\n",
      "           1       0.82      0.86      0.84       222\n",
      "\n",
      "    accuracy                           0.83       448\n",
      "   macro avg       0.83      0.83      0.83       448\n",
      "weighted avg       0.83      0.83      0.83       448\n",
      "\n",
      "Accuracy using RandomForestClassifier: 83.26%\n",
      "\n",
      "-------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "acc_RANDOM = []\n",
    "current_directory = 'C:\\\\Users\\\\Atit Acharya\\\\OneDrive - The University of Texas at Tyler\\\\Desktop\\\\Research\\\\Classification\\\\XGBOOST'\n",
    "# print(current_directory)\n",
    "for filename in os.listdir(current_directory):\n",
    "#     print(filename)\n",
    "    if os.path.isfile(os.path.join(current_directory, filename)) and '.csv' in filename:\n",
    "#         # Do something with the file\n",
    "        print(\"\\n-------------------------------------------------------------------\\n\")\n",
    "        data = pd.read_csv(filename)\n",
    "        \n",
    "        # Split data into features (X) and target (y)\n",
    "        X = data.drop(['LastStatementMinimumPaymentDueAmount', 'CardExternalStatus', 'Target', 'LastStatementBalanceAmount'] , axis=1)\n",
    "#         X = data.drop('Target', axis=1)\n",
    "        y = data['Target']\n",
    "        \n",
    "       # Split data into training, validation, and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Train random forest classifier\n",
    "        rfc = RandomForestClassifier(random_state=42)\n",
    "        \n",
    "        # Define grid search parameters\n",
    "#         param_grid = {\n",
    "#                  'n_estimators': [100, 200, 300],\n",
    "#                  'max_depth': [5, 10, 20],\n",
    "#                  'min_samples_split': [2, 5, 10],\n",
    "#                  'min_samples_leaf': [1, 2, 4],\n",
    "#                     }\n",
    "        param_grid = {\n",
    "                    'n_estimators': [300],\n",
    "                    'max_depth': [20],\n",
    "                    'min_samples_split': [10],\n",
    "                    'min_samples_leaf': [4],\n",
    "}\n",
    "        \n",
    "        # Perform grid search on the training set\n",
    "        grid_search = GridSearchCV(rfc, param_grid=param_grid, cv=5)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Get best hyperparameters\n",
    "        best_params = grid_search.best_params_\n",
    "        \n",
    "        # Train the classifier on the entire training set using the best hyperparameters\n",
    "        rfc = RandomForestClassifier(random_state=42, **best_params)\n",
    "        rfc.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate the classifier on the validation set\n",
    "        y_val_pred = rfc.predict(X_val)\n",
    "        print('Validation Classification Report:')\n",
    "        print(classification_report(y_val, y_val_pred))\n",
    "        \n",
    "        # Evaluate the classifier on the test set\n",
    "        y_test_pred = rfc.predict(X_test)\n",
    "        print('Test Classification Report:')\n",
    "        print(classification_report(y_test, y_test_pred))\n",
    "        \n",
    "        \n",
    "        RandomForestClassifier_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        print('Accuracy using RandomForestClassifier: {:.2f}%'.format(RandomForestClassifier_accuracy * 100))\n",
    "\n",
    "        \n",
    "        acc_RANDOM.append(RandomForestClassifier_accuracy)\n",
    "\n",
    "Average_RandomClassifier = np.mean(acc_RANDOM)\n",
    "print(Average_RandomClassifier)\n",
    "\n",
    "        \n",
    "        \n",
    "        # # generate a random dataset\n",
    "        # X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=42)\n",
    "        #\n",
    "        # # fit a random forest classifier\n",
    "        # rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        # rfc.fit(X, y)\n",
    "        #\n",
    "        # # extract the first tree from the forest\n",
    "        # tree = rfc.estimators_[0]\n",
    "        #\n",
    "        # # export the tree to a Graphviz dot file\n",
    "        # dot_data = export_graphviz(tree, out_file=None,\n",
    "        #                    feature_names=['feature_{}'.format(i) for i in range(X.shape[1])],\n",
    "        #                    class_names=['class_0', 'class_1'],\n",
    "        #                    filled=True, rounded=True, special_characters=True)\n",
    "        # create a Graphviz graph from the dot file\n",
    "        # graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "        # graph\n",
    "        \n",
    "        # display the graph as an image\n",
    "        # Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6488f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
